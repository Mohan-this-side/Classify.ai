# Classify AI: Product Requirements Document

## Executive Summary

**Product Name:** Classify AI  
**Mission:** To make machine learning accessible to non-experts by automating the end-to-end classification pipeline through a multi-agent LLM system.  
**Target Audience:** Non-technical domain experts, data analysts, and ML engineers looking to automate prototyping.  
**Value Proposition:** Users can upload a dataset, specify a prediction goal, and receive a cleaned dataset, a trained model, a reproducible Jupyter notebook, and a detailed report, all while learning and maintaining control through an interactive, secure, and transparent process. The system uses a sophisticated double-layer agentic framework where each agent performs hardcoded analysis followed by LLM-generated custom code execution in secure Docker sandboxes, with real-time project management providing educational explanations throughout the process.

## Problem Statement

Building predictive models is complex, requiring expertise in coding, statistics, and machine learning. Current solutions either:
- Require extensive technical knowledge (scikit-learn, pandas, etc.)
- Are black-box solutions that don't teach users
- Lack transparency and user control
- Don't prevent common pitfalls like data leakage

Classify AI removes these barriers by providing an intelligent, educational, and secure platform that guides users through the entire ML pipeline while maintaining transparency and control.

## Core Features

### F1: Simple User Interface
- Clean web UI for file upload (CSV/Excel)
- Target column specification
- LLM API key input (Gemini/OpenAI/Anthropic)
- Real-time workflow progress visualization
- Dedicated Project Manager window with live explanations
- Approval gate interactions
- Results download interface
- Educational content display with code snippets

### F2: Double-Layer Multi-Agent Workflow Engine
- LangGraph orchestration managing 8 specialized AI agents
- **Double-Layer Architecture:** Each agent uses hardcoded analysis + LLM code generation
- **Layer 1:** Pre-written Python functions perform comprehensive data analysis
- **Layer 2:** LLM generates custom, dataset-specific code based on analysis results
- Sequential and parallel agent execution with context awareness
- State persistence and checkpointing with agent memory
- Automatic error recovery and self-healing
- Human-in-the-loop approval gates
- Real-time project management coordination

### F3: Human-in-the-Loop Approval Gates
- Key decision points where workflow pauses
- User approval required for critical decisions
- Educational explanations of proposed actions
- Options to approve, modify, or reject proposals
- Transparent reasoning for each decision

### F4: Secure Sandboxed Code Execution Pipeline
- **Docker-based isolation** for all LLM-generated code execution
- **No network access**, limited resources, non-root execution
- **CPU, memory, and execution time limits** with monitoring
- **Multi-layer security validation** before sandbox execution
- **Generated Code Validation:** Syntax, security, and logical validation
- **Complete audit trail** of all generated and executed code
- **Automatic cleanup** and resource management
- **Sandbox Resource Monitoring** with real-time alerts

### F5: Automated Data Leakage Prevention
- Enforced use of sklearn.pipeline.Pipeline
- Automated detection of preprocessing before train/test split
- Educational explanations of data leakage concepts
- Validation at multiple stages
- Clear warnings and guidance

### F6: Real-Time Project Management System
- **Live Code Analysis:** Reads and analyzes code generated by ALL agents in real-time
- **Educational Explanations:** Uses LLM to provide human-readable explanations of technical concepts
- **Data Science Education:** Explains concepts like "imputation", "feature engineering", "cross-validation"
- **Real-Time User Communication:** Provides live updates as agents work
- **Plain English Descriptions:** Explains data transformations in simple terms
- **Interactive Q&A:** Users can ask questions about the process
- **Frontend Integration:** Dedicated Project Manager window with streaming updates

### F7: Comprehensive Deliverables
- Cleaned dataset (CSV)
- Trained model (.joblib file)
- Reproducible Jupyter Notebook (.ipynb)
- Detailed technical report (.md)
- Educational content throughout
- Complete audit trail of all generated code

## Technical Architecture

### Layer 1: Presentation (Frontend)
- **Technology:** Next.js with React
- **Responsibilities:**
  - File upload handling
  - Real-time progress display
  - Project Manager window with live explanations
  - Approval gate UI
  - Results visualization
  - WebSocket communication
  - Educational content display with code snippets
- **Key Components:**
  - File upload component
  - Progress tracker
  - Project Manager interface with streaming updates
  - Approval decision interface
  - Results viewer
  - Educational content display
  - Interactive Q&A system

### Layer 2: Double-Layer Processing Engine (Backend)
- **Technology:** FastAPI with LangGraph
- **Responsibilities:**
  - Multi-agent workflow orchestration with double-layer architecture
  - State management and persistence with agent memory
  - API endpoints for frontend
  - WebSocket real-time updates
  - Agent communication coordination
  - LLM code generation pipeline
  - Docker sandbox execution environment
  - Real-time project management system
- **Key Components:**
  - LangGraph workflow engine
  - Double-layer processing engine
  - State management system with context awareness
  - Agent coordination logic
  - LLM code generation pipeline
  - Docker sandbox execution environment
  - Real-time project management system
  - Agent memory and context management
  - API route handlers
  - WebSocket handlers

### Layer 3: Infrastructure
- **Database:** PostgreSQL for state persistence and agent memory
- **Cache/Broker:** Redis for task queues and caching
- **Sandbox:** Docker containers for secure code execution
- **Storage:** File system for artifacts, datasets, and generated code
- **Monitoring:** Comprehensive logging, metrics, and sandbox resource monitoring
- **LLM Services:** Integration with Gemini, OpenAI, and Anthropic APIs
- **Security:** Multi-layer code validation and audit logging

## Agent Architecture

### Double-Layer Framework Overview

Each agent (except Project Manager) follows a sophisticated **double-layer architecture**:

**Layer 1 - Hardcoded Analysis Layer:**
- Pre-written Python functions perform comprehensive data analysis
- Generates detailed statistical analysis, data quality metrics, and insights
- Provides robust, reliable analysis that never fails
- Outputs structured analysis results (missing values, data types, outliers, correlations, etc.)

**Layer 2 - LLM Code Generation Layer:**
- Takes hardcoded analysis results as input
- Uses LLM (Gemini/OpenAI/Anthropic) to generate custom Python code
- Generates robust, dataset-specific cleaning/processing code with detailed comments
- Code is tailored to the specific characteristics of the uploaded dataset

**Sandbox Execution:**
- Generated code from Layer 2 is executed in Docker sandbox
- Sandbox provides secure, isolated environment with no network access
- Execution results (cleaned dataset, processed data) are returned to the workflow
- Each agent's output becomes input for the next agent
- Complete audit trail of all generated and executed code

### Core Agents (MVP - Phase 1)

#### 1. Data Cleaning Agent
- **Purpose:** Handle missing values and comprehensive data cleaning using double-layer approach
- **Input:** Raw dataset path, data schema
- **Output:** Cleaned dataset path, generated cleaning code, detailed reasoning
- **Layer 1 Features:**
  - Missing value analysis and statistical summaries
  - Data type validation and detection
  - Outlier detection with statistical methods
  - Data quality assessment
- **Layer 2 Features:**
  - LLM generates custom cleaning code based on analysis
  - Dataset-specific imputation strategies
  - Intelligent data type conversions
  - Educational explanations of cleaning decisions

#### 2. Model Builder Agent
- **Purpose:** Train classification models with data leakage prevention using double-layer approach
- **Input:** Cleaned dataset path, target column, previous agent context
- **Output:** Trained model path, generated training code, performance metrics
- **Layer 1 Features:**
  - Model performance analysis and comparison
  - Cross-validation strategy evaluation
  - Feature importance analysis
  - Data leakage detection
- **Layer 2 Features:**
  - LLM generates custom model training code
  - Enforced sklearn.pipeline.Pipeline usage
  - Dataset-specific hyperparameter optimization
  - Educational explanations of model choices

#### 3. Model Evaluation Agent
- **Purpose:** Calculate and report model performance using double-layer approach
- **Input:** Trained model, test dataset, previous agent context
- **Output:** Performance metrics, generated evaluation code, visualizations
- **Layer 1 Features:**
  - Comprehensive performance metric calculations
  - Statistical significance testing
  - Model comparison analysis
  - Visualization data preparation
- **Layer 2 Features:**
  - LLM generates custom evaluation code
  - Multiple metric calculations (accuracy, F1, precision, recall, ROC-AUC)
  - Confusion matrix and ROC curve generation
  - Educational performance interpretation

#### 4. Technical Reporter Agent
- **Purpose:** Generate comprehensive Jupyter notebook and report using double-layer approach
- **Input:** All agent code, results, metrics, complete workflow context
- **Output:** Jupyter notebook, technical report, usage instructions
- **Layer 1 Features:**
  - Code analysis and organization
  - Report structure planning
  - Educational content outline
  - Technical documentation preparation
- **Layer 2 Features:**
  - LLM generates comprehensive documentation
  - Code compilation and organization
  - Educational content generation
  - Markdown explanations with code snippets
  - Usage instructions and best practices

### Advanced Agents (Phase 2)

#### 5. EDA (Exploratory Data Analysis) Agent
- **Purpose:** Generate comprehensive data analysis and visualizations using double-layer approach
- **Layer 1 Features:**
  - Statistical summaries and data profiling
  - Distribution analysis and outlier detection
  - Correlation and relationship analysis
  - Data quality assessment
- **Layer 2 Features:**
  - LLM generates custom visualization code
  - Interactive plot generation
  - Educational explanations of data patterns
  - Dataset-specific insights

#### 6. Feature Engineering Agent
- **Purpose:** Create and select optimal features using double-layer approach
- **Layer 1 Features:**
  - Feature importance analysis
  - Feature correlation analysis
  - Data type analysis for feature creation
  - Feature selection strategy evaluation
- **Layer 2 Features:**
  - LLM generates custom feature engineering code
  - Automated feature creation strategies
  - Dataset-specific encoding approaches
  - Educational explanations of feature choices

#### 7. Data Discovery Agent
- **Purpose:** Analyze data quality and provide insights using double-layer approach
- **Layer 1 Features:**
  - Comprehensive data quality assessment
  - Schema analysis and validation
  - Pattern recognition and anomaly detection
  - Data completeness analysis
- **Layer 2 Features:**
  - LLM generates custom analysis code
  - Intelligent data quality recommendations
  - Educational explanations of data issues
  - Dataset-specific insights and recommendations

### Real-Time Project Management Agent

#### 8. Project Manager Agent
- **Purpose:** Sophisticated real-time coordinator and educational guide
- **Key Features:**
  - **Real-Time Code Analysis:** Reads and analyzes code generated by ALL agents in real-time
  - **Educational Explanations:** Uses LLM to provide human-readable explanations of technical concepts
  - **Data Science Education:** Explains concepts like "imputation", "feature engineering", "cross-validation"
  - **Live User Communication:** Provides real-time updates to frontend users as agents work
  - **Plain English Descriptions:** Explains data transformations in simple terms
  - **Context Awareness:** Maintains memory of all previous agent work and decisions
  - **Interactive Q&A:** Users can ask questions about the process
  - **Frontend Integration:** Dedicated Project Manager window with streaming updates
  - **Educational Focus:** Teaches users about ML best practices and data science concepts

## User Experience Flow

### Primary User Journey
1. **Upload Dataset:** User uploads CSV/Excel file
2. **Specify Target:** User selects target column for prediction
3. **Provide API Key:** User enters LLM API key (Gemini/OpenAI/Anthropic)
4. **Agentic Framework Activation:** System starts double-layer processing
5. **Real-Time Project Management:** User sees live explanations of what's happening
6. **Layer 1 Analysis:** Hardcoded analysis runs (user sees progress and insights)
7. **Layer 2 Code Generation:** LLM generates custom code (user sees explanation)
8. **Sandbox Execution:** Code runs in Docker (user sees results and explanations)
9. **Project Manager Updates:** User gets real-time explanations of each step
10. **Sequential Processing:** Each agent builds on previous work with context awareness
11. **Approval Gates:** User approves key decisions with educational explanations
12. **Final Deliverables:** User receives cleaned dataset, model, notebook, report
13. **Learning Experience:** User understands the process through continuous educational content

### Approval Gate Examples
- **Data Cleaning Gate:** "We found that column 'age' has 42 missing values. Based on our analysis, we recommend median imputation because the data is normally distributed. This will preserve the statistical properties of your dataset. Approve this approach?"
- **Feature Engineering Gate:** "We discovered 3 categorical variables that need encoding. We suggest one-hot encoding which will create 15 new features. This approach is ideal for your dataset size and will improve model performance. Proceed with this strategy?"
- **Model Training Gate:** "After analyzing your data, we recommend RandomForest with 100 estimators. This algorithm works well with your feature set and will provide good interpretability. Estimated training time: 2 minutes. Continue with this model?"

### Sequential Agent Awareness
- **Context Memory:** Each agent maintains awareness of all previous agents' work
- **Decision Continuity:** Agents build upon previous decisions and transformations
- **Single LLM Thread:** Uses continuous conversation thread to maintain memory
- **No Information Loss:** Complete context preservation between agent transitions
- **Intelligent Progression:** Each agent makes informed decisions based on full workflow history

## Security and Safety Requirements

### Generated Code Validation (Multi-Layer)
1. **Syntax Validation:** Python AST parsing and syntax checking
2. **Security Validation:** Forbidden imports/functions detection
3. **Logical Validation:** ML best practices enforcement
4. **Execution Validation:** Sandbox testing before production execution
5. **Generated Code Security Scanning:** Automated security analysis of LLM-generated code
6. **Code Quality Validation:** Performance and efficiency checks
7. **Generated Code Audit Trail:** Complete logging of all generated and executed code

### Sandbox Security
- **Isolation:** Docker containers with no network access
- **Resource Limits:** CPU, memory, and execution time constraints with monitoring
- **User Permissions:** Non-root execution
- **File System:** Restricted access to specific directories
- **Sandbox Resource Monitoring:** Real-time monitoring of resource usage
- **Execution Time Limits:** Configurable timeouts for code execution
- **Memory Limits:** Strict memory constraints to prevent resource exhaustion

### Data Protection
- **Encryption:** API keys and sensitive data
- **Access Control:** User-specific data isolation
- **Audit Logging:** Complete activity tracking
- **Data Retention:** Configurable cleanup policies

## Performance Requirements

### Response Times
- **File Upload:** < 5 seconds for files up to 100MB
- **Layer 1 Analysis:** < 10 seconds per agent
- **LLM Code Generation:** < 30 seconds per agent
- **Sandbox Execution:** < 60 seconds per agent
- **Total Pipeline:** < 15 minutes for typical datasets
- **WebSocket Updates:** < 100ms latency
- **Real-Time Update Latency:** < 2 seconds
- **Project Manager Response Time:** < 5 seconds

### Scalability
- **Concurrent Users:** Support 50+ simultaneous workflows
- **Dataset Size:** Handle up to 1M rows, 1000 features
- **Throughput:** Process 100+ datasets per day
- **Availability:** 99.9% uptime

### Quality Metrics
- **Success Rate:** >90% of workflows complete successfully
- **Model Performance:** Within 10% of human expert performance
- **Code Quality:** >95% of generated code executes without errors
- **User Satisfaction:** >4.5/5 rating

## Development Phases

### Phase 1: MVP (Weeks 1-3)
**Goal:** Functional end-to-end pipeline with double-layer architecture and core safety features

**Features:**
- [P1-F1] Foundational Backend: FastAPI, PostgreSQL, Redis
- [P1-F2] Double-Layer Processing Engine: Hardcoded analysis + LLM code generation
- [P1-F3] Secure Code Execution Sandbox: Docker-based isolation
- [P1-F4] LangGraph Workflow: Basic agent orchestration with context awareness
- [P1-F5] Core Agents: Data Cleaning, Model Builder, Evaluation, Reporter (double-layer)
- [P1-F6] Basic Frontend: File upload, progress display, results download
- [P1-F7] Project Manager Agent: Basic real-time coordination

**Success Criteria:**
- Complete double-layer pipeline works on Iris dataset
- All four deliverables generated with custom code
- At least one approval gate functional
- F1 score within 20% of baseline
- Real-time project management working

### Phase 2: Enhanced Interactivity (Weeks 4-6)
**Goal:** Human-in-the-loop control, advanced agents, and sophisticated project management

**Features:**
- [P2-F1] Approval Gates: Full interrupt/resume functionality with educational explanations
- [P2-F2] Advanced Agents: EDA, Feature Engineering, Data Discovery (double-layer)
- [P2-F3] Real-Time UI: WebSocket updates, progress visualization, Project Manager window
- [P2-F4] Self-Healing: Iterative code refinement and error recovery
- [P2-F5] Enhanced Project Manager: Full real-time coordination and educational features
- [P2-F6] Sequential Agent Awareness: Complete context memory and intelligent progression

**Success Criteria:**
- All approval gates working with educational explanations
- Real-time updates and Project Manager window functional
- Self-healing reduces failures by 50%
- Advanced agents working with double-layer architecture
- Tested on 3+ different datasets

### Phase 3: Production Readiness (Weeks 7-9)
**Goal:** Polish, scalability, and professional user experience with full double-layer architecture

**Features:**
- [P3-F1] Full Agent Suite: All 8 agents operational with double-layer architecture
- [P3-F2] Comprehensive Reporting: Polished notebooks and reports with generated code
- [P3-F3] Scalable Infrastructure: Docker Compose, Kubernetes with sandbox orchestration
- [P3-F4] Polished UI: Professional design, educational content, Project Manager interface
- [P3-F5] Advanced Security: Complete code validation and audit trail
- [P3-F6] Performance Optimization: Optimized LLM calls and sandbox execution

**Success Criteria:**
- All 8 agents working with double-layer architecture
- Professional UI/UX with real-time project management
- Scalable deployment with sandbox orchestration
- Production monitoring and security validation
- Complete educational experience for users

## Technical Requirements

### Backend Requirements
- **Framework:** FastAPI 0.104+
- **Python:** 3.11+
- **Database:** PostgreSQL 15+
- **Cache:** Redis 7+
- **Orchestration:** LangGraph 0.2+
- **ML Libraries:** scikit-learn, pandas, numpy, matplotlib, seaborn
- **LLM Services:** Gemini API, OpenAI API, Anthropic API
- **Containerization:** Docker 24+ for sandbox execution
- **Code Validation:** AST parsing, security scanning libraries

### Frontend Requirements
- **Framework:** Next.js 14+
- **Language:** TypeScript
- **UI Library:** React 18+
- **WebSocket:** Socket.io for real-time updates
- **File Handling:** react-dropzone
- **Styling:** Tailwind CSS
- **Real-Time Components:** Project Manager interface, streaming updates
- **Educational Components:** Code snippet display, interactive Q&A

### Infrastructure Requirements
- **Containerization:** Docker 24+ for application and sandbox containers
- **Orchestration:** Docker Compose (dev), Kubernetes (prod)
- **Monitoring:** Prometheus, Grafana with sandbox resource monitoring
- **Logging:** Structured logging with ELK stack and code audit trail
- **Security:** HTTPS, API key management, multi-layer code validation
- **Sandbox Infrastructure:** Isolated execution environment with resource limits

### API Requirements
- **Authentication:** API key-based
- **Rate Limiting:** 100 requests/minute per user
- **File Upload:** Multipart form data, 100MB limit
- **WebSocket:** Real-time bidirectional communication
- **Error Handling:** Comprehensive error responses

## Data Requirements

### Input Data
- **Formats:** CSV, Excel (.xlsx, .xls)
- **Size Limits:** 1M rows, 1000 features, 100MB file size
- **Data Types:** Numeric, categorical, text, datetime
- **Quality:** Handles missing values, outliers, inconsistencies

### Output Data
- **Cleaned Dataset:** CSV format with same structure
- **Trained Model:** Joblib serialized sklearn pipeline
- **Jupyter Notebook:** .ipynb format with educational content
- **Technical Report:** Markdown format with metrics and insights

### State Management
- **State Object:** JSON-serializable Pydantic model
- **Persistence:** PostgreSQL with JSON columns
- **Checkpointing:** After each agent execution
- **Recovery:** Automatic resume from last checkpoint

## Quality Assurance

### Testing Strategy
- **Unit Tests:** Individual agent functions
- **Integration Tests:** Agent interactions
- **End-to-End Tests:** Complete workflow
- **Performance Tests:** Load and stress testing
- **Security Tests:** Penetration testing

### Benchmark Datasets
- **Tier 1 (Development):** Iris, Titanic, Wine Quality
- **Tier 2 (Validation):** Credit Card Fraud, Heart Disease
- **Tier 3 (Production):** Kaggle competition datasets

### Success Metrics
- **Performance:** F1 score within 10% of human expert
- **Reliability:** >90% success rate
- **Security:** Zero security violations
- **Usability:** <5 minutes to complete workflow

## Risk Mitigation

### Technical Risks
- **LLM Code Generation Failures:** Self-healing loops, fallback strategies
- **Data Leakage:** Multiple validation layers, pipeline enforcement
- **Security Breaches:** Multi-layer security, sandbox isolation
- **State Persistence Failures:** Frequent checkpointing, transaction safety

### Business Risks
- **Scope Creep:** Phased development, strict MVP focus
- **Timeline Delays:** Buffer time, parallel development
- **User Adoption:** Educational focus, transparent process
- **Performance Issues:** Early optimization, monitoring

## Success Criteria

### Minimum Viable Product (MVP)
- ✅ System accepts uploaded CSV
- ✅ Shows real-time agent progress
- ✅ At least one approval gate works
- ✅ Generates trained model
- ✅ Produces executable Jupyter notebook
- ✅ F1 score within 20% of baseline

### Ideal Product
- ✅ All MVP features
- ✅ 4+ agents fully functional
- ✅ F1 score within 10% of baseline
- ✅ Tested on 3+ datasets
- ✅ Professional UI/UX
- ✅ Clear educational explanations

### Stretch Goals
- ✅ All ideal features
- ✅ 6+ agents operational
- ✅ Beautiful visualizations
- ✅ Polished user experience
- ✅ Advanced reporting features

## Conclusion

Classify AI represents a revolutionary advancement in making machine learning accessible to non-experts through its sophisticated double-layer agentic framework and real-time project management system. The system combines the reliability of hardcoded analysis with the intelligence of LLM-generated custom code, all executed in secure Docker sandboxes while providing continuous educational guidance to users.

The phased development approach ensures a working MVP while building toward a comprehensive, production-ready platform that works like a senior data scientist explaining their work in real-time.

The success of this project depends on:
1. **Reliable Double-Layer Architecture:** Hardcoded analysis + LLM code generation with robust validation
2. **Secure Sandbox Execution:** Docker-based isolation with comprehensive code validation
3. **Real-Time Project Management:** Continuous educational guidance and user communication
4. **Sequential Agent Awareness:** Context memory and intelligent progression through the workflow
5. **Zero Data Leakage:** Enforced best practices and multiple validation layers
6. **User Trust:** Transparency, education, and human-in-the-loop control
7. **Robustness:** Comprehensive testing and graceful failure handling

This PRD provides the foundation for building a world-class ML automation platform that empowers users through education while maintaining the highest technical and security standards. The system transforms complex data science workflows into an interactive, educational experience that teaches users while delivering professional-grade results.