"""
🦜🔗 LangChain-Powered Data Cleaning Agent
==========================================

This is a complete rewrite of the data cleaning agent using LangChain ecosystem:
- LangChain chat models for robust AI interactions
- Structured prompt templates with variable injection
- Output parsers for reliable code generation
- LangSmith tracing for complete observability
- Error handling with automatic retries
- Structured data validation with Pydantic

🆚 Comparison with Original Agent:
Original: Direct API calls, string manipulation, basic error handling
Enhanced: Professional framework, structured I/O, comprehensive monitoring
"""

import pandas as pd
import numpy as np
import logging
import time
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
import json
import traceback

# LangChain Imports
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate
from langchain_core.output_parsers import PydanticOutputParser, BaseOutputParser
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.runnables import RunnablePassthrough
from langchain_core.callbacks import BaseCallbackHandler

# Pydantic for structured outputs
from pydantic import BaseModel, Field, validator
from typing import Union

# Local imports
from config import config
from code_executor import SafeCodeExecutor

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DatasetAnalysis(BaseModel):
    """
    📊 Structured output for dataset analysis
    
    This ensures the AI returns consistent, parseable analysis results
    instead of free-form text that needs manual parsing.
    """
    
    # Basic dataset information
    total_rows: int = Field(description="Total number of rows in the dataset")
    total_columns: int = Field(description="Total number of columns in the dataset")
    memory_usage_mb: float = Field(description="Memory usage in megabytes")
    
    # Data quality issues
    missing_values_count: int = Field(description="Total number of missing values")
    duplicate_rows_count: int = Field(description="Number of duplicate rows")
    
    # Column analysis
    numeric_columns: List[str] = Field(description="List of numeric column names")
    categorical_columns: List[str] = Field(description="List of categorical column names")
    datetime_columns: List[str] = Field(description="List of datetime column names")
    
    # Quality assessment
    data_quality_score: float = Field(description="Overall data quality score (0-100)", ge=0, le=100)
    major_issues: List[str] = Field(description="List of major data quality issues found")
    recommended_actions: List[str] = Field(description="Recommended cleaning actions")
    
    # Statistical insights
    corruption_indicators: List[str] = Field(description="Indicators of data corruption")
    outlier_columns: List[str] = Field(description="Columns with potential outliers")

class CleaningCode(BaseModel):
    """
    🤖 Structured output for generated cleaning code
    
    This ensures the AI returns properly formatted, executable code
    with metadata for better error handling and debugging.
    """
    
    # Core code
    cleaning_code: str = Field(description="Complete Python code for data cleaning")
    explanation: str = Field(description="Human-readable explanation of what the code does")
    
    # Expected results
    expected_changes: List[str] = Field(description="List of expected changes to the dataset")
    estimated_processing_time: str = Field(description="Estimated time to process the dataset")
    
    # Quality assurance
    validation_checks: List[str] = Field(description="List of validation checks performed")
    potential_risks: List[str] = Field(description="Potential risks or considerations")
    
    # Metadata
    generated_at: str = Field(default_factory=lambda: datetime.now().isoformat())
    model_used: str = Field(description="AI model used for code generation")

class CustomTraceHandler(BaseCallbackHandler):
    """
    📊 Custom callback for enhanced logging and monitoring
    
    This captures detailed information about each AI interaction
    for debugging and optimization purposes.
    """
    
    def __init__(self):
        self.traces = []
    
    def on_llm_start(self, serialized: Dict[str, Any], prompts: List[str], **kwargs) -> None:
        """Called when LLM starts processing"""
        logger.info(f"🤖 LLM processing started with {len(prompts)} prompt(s)")
        self.traces.append({
            "event": "llm_start",
            "timestamp": datetime.now().isoformat(),
            "prompt_count": len(prompts),
            "model": serialized.get("name", "unknown")
        })
    
    def on_llm_end(self, response, **kwargs) -> None:
        """Called when LLM finishes processing"""
        logger.info("✅ LLM processing completed")
        self.traces.append({
            "event": "llm_end",
            "timestamp": datetime.now().isoformat(),
            "token_usage": getattr(response, 'llm_output', {}).get('token_usage', {})
        })
    
    def on_llm_error(self, error: Exception, **kwargs) -> None:
        """Called when LLM encounters an error"""
        logger.error(f"❌ LLM error: {str(error)}")
        self.traces.append({
            "event": "llm_error",
            "timestamp": datetime.now().isoformat(),
            "error": str(error)
        })

class LangChainDataCleaningAgent:
    """
    🦜🔗 Professional Data Cleaning Agent powered by LangChain
    
    Key Improvements over Original Agent:
    ===================================
    
    1. **Structured I/O**: Uses Pydantic models for reliable data parsing
    2. **Professional Prompts**: Template-based prompts with proper variable injection
    3. **Error Handling**: Automatic retries with exponential backoff
    4. **Observability**: Full LangSmith tracing and monitoring
    5. **Type Safety**: Strong typing throughout the system
    6. **Modularity**: Separate components for analysis, generation, and execution
    """
    
    def __init__(self):
        """Initialize the LangChain-powered agent"""
        
        logger.info("🚀 Initializing LangChain Data Cleaning Agent...")
        
        # Initialize code executor (reuse existing safe execution)
        self.code_executor = SafeCodeExecutor()
        
        # Initialize LangChain chat model
        self.llm = self._setup_chat_model()
        
        # Initialize prompt templates
        self.analysis_chain = self._setup_analysis_chain()
        self.code_generation_chain = self._setup_code_generation_chain()
        self.correction_chain = self._setup_correction_chain()
        
        # Initialize callback handler for monitoring
        self.trace_handler = CustomTraceHandler()
        
        logger.info("✅ LangChain agent initialized successfully!")
        
    def _setup_chat_model(self) -> ChatGoogleGenerativeAI:
        """
        🤖 Initialize LangChain chat model with optimal settings
        
        Benefits over direct API calls:
        - Automatic retries and error handling
        - Token counting and cost tracking
        - Multiple provider support (easy to switch to OpenAI/Claude)
        - Built-in streaming support
        - Integration with LangSmith tracing
        """
        
        if not config.google_api_key:
            raise ValueError("Google API key not found. Please set GOOGLE_API_KEY in your .env file")
        
        model_config = config.get_model_config()
        
        # Create LangChain chat model
        llm = ChatGoogleGenerativeAI(
            model=model_config["model"],
            temperature=model_config["temperature"],
            max_tokens=model_config["max_tokens"],
            api_key=model_config["api_key"],
            streaming=model_config["streaming"],
            verbose=True  # Enable detailed logging
        )
        
        logger.info(f"🤖 Chat model initialized: {model_config['model']}")
        logger.info(f"🎯 Temperature: {model_config['temperature']}")
        logger.info(f"📊 Max tokens: {model_config['max_tokens']}")
        
        return llm
    
    def _setup_analysis_chain(self):
        """
        📊 Create structured analysis chain with prompt templates
        
        This replaces the string-based prompts with professional templates
        that ensure consistent variable injection and output parsing.
        """
        
        # Create output parser for structured analysis
        self.analysis_parser = PydanticOutputParser(pydantic_object=DatasetAnalysis)
        
        # Create system prompt template
        system_template = """You are an expert data scientist specializing in data quality assessment and cleaning strategy.

Your task is to analyze datasets and provide comprehensive insights for cleaning and improvement.

**CRITICAL: You MUST respond with VALID JSON only. No explanatory text before or after the JSON.**

Key Analysis Areas:
1. **Data Structure**: Examine shape, types, and memory usage
2. **Quality Issues**: Identify missing values, duplicates, and inconsistencies  
3. **Data Corruption**: Detect corrupted values that need special handling
4. **Statistical Profile**: Understand distributions and identify outliers
5. **Domain Context**: Consider the type of data and appropriate cleaning strategies

{format_instructions}

**FORMATTING REQUIREMENTS:**
- Start your response immediately with {{
- End your response with }}
- Use double quotes for all strings
- Ensure all JSON fields are present and properly formatted
- Do not include markdown code blocks, explanations, or any text outside the JSON

**EXAMPLE START:**
{{
  "total_rows": 150,
  "total_columns": 5,
  ...

**IMPORTANT: Your response must be a single valid JSON object that matches the required schema exactly. Do not include any text outside the JSON.**"""

        human_template = """Please analyze this dataset:

**Dataset Information:**
- Shape: {dataset_shape}
- Memory Usage: {memory_usage} MB
- Columns: {column_info}

**Sample Data:**
{sample_data}

**Column Details:**
{column_details}

**Missing Values:**
{missing_values_info}

**Data Quality Observations:**
{quality_observations}

Based on this information, provide a comprehensive analysis with specific recommendations for data cleaning."""

        # Create prompt template
        prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(system_template),
            HumanMessagePromptTemplate.from_template(human_template)
        ])
        
        # Create the chain: prompt -> llm -> parser
        chain = prompt | self.llm | self.analysis_parser
        
        logger.info("📊 Analysis chain created with structured output parsing")
        return chain
    
    def _setup_code_generation_chain(self):
        """
        🤖 Create code generation chain with structured output
        
        This ensures the AI generates properly formatted, executable code
        with comprehensive metadata for debugging and validation.
        """
        
        # Create output parser for structured code
        self.code_parser = PydanticOutputParser(pydantic_object=CleaningCode)
        
        system_template = """You are an expert Python data scientist who generates robust, production-ready data cleaning code.

**CRITICAL: You MUST respond with VALID JSON only. No explanatory text before or after the JSON.**

**CRITICAL REQUIREMENTS:**
1. Generate ONLY executable Python code - NO import statements allowed
2. Use pre-available variables: pd, np, df, sklearn classes
3. Ensure ALL operations preserve DataFrame structure and indexing
4. Handle edge cases and corrupted data intelligently
5. NEVER leave missing values - use statistical imputation
6. Add comprehensive validation and error checking

**Pre-imported Libraries Available:**
- pandas as pd
- numpy as np  
- sklearn: StandardScaler, SimpleImputer, KNNImputer, etc.

**Code Structure Requirements:**
```python
# Step 1: Initialize and validate
cleaned_df = df.copy()
print(f"Starting shape: {{cleaned_df.shape}}")

# Step 2: Handle data types and corruption
# [Your intelligent type conversion code]

# Step 3: Statistical imputation (NO missing values allowed)
# [Your robust imputation code]

# Step 4: Outlier detection and handling
# [Your outlier management code]

# Step 5: Remove duplicates
# [Your duplicate removal code]

# Step 6: Final validation
assert cleaned_df.isnull().sum().sum() == 0, "Missing values still present!"
print(f"Final shape: {{cleaned_df.shape}}")
print("✅ Cleaning completed successfully!")
```

{format_instructions}

**JSON FORMATTING REQUIREMENTS:**
- Start your response immediately with {{
- End your response with }}
- Use double quotes for all strings in JSON
- Escape any quotes within code strings using \"
- Ensure all required JSON fields are present
- Do not include markdown code blocks, explanations, or any text outside the JSON

**EXAMPLE JSON START:**
{{
  "cleaning_code": "# Step 1: Initialize and validate\\ncleaned_df = df.copy()\\n...",
  "explanation": "This code handles...",
  ...

Generate code that handles ANY dataset robustly and passes all validation checks."""

        human_template = """Generate data cleaning code for this dataset:

**Dataset Analysis:**
{analysis_results}

**Specific Requirements:**
- Handle corrupted values in: {corruption_details}
- Impute missing values using statistical methods
- Remove duplicates safely
- Optimize data types for memory efficiency
- Ensure zero missing values in final result

**Pre-execution Context:**
```python
# These variables are already available:
# df = original_dataset
# pd = pandas library
# np = numpy library
# StandardScaler, SimpleImputer, etc. from sklearn
```

Generate comprehensive cleaning code that transforms this dataset into production-ready format."""

        # Create prompt template
        prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(system_template),
            HumanMessagePromptTemplate.from_template(human_template)
        ])
        
        # Create the chain
        chain = prompt | self.llm | self.code_parser
        
        logger.info("🤖 Code generation chain created with structured output")
        return chain
    
    def _setup_correction_chain(self):
        """
        🔧 Create error correction chain for self-healing capabilities
        
        This provides intelligent error analysis and code correction
        based on execution failures and specific error patterns.
        """
        
        # Use the same parser as code generation
        # (Already created in _setup_code_generation_chain as self.code_parser)
        
        system_template = """You are an expert debugger specializing in data cleaning code errors.

Your task is to analyze execution errors and generate corrected code that resolves the specific issues.

**Error Analysis Framework:**
1. **Root Cause Analysis**: Identify the exact cause of the error
2. **Context Understanding**: Consider the dataset characteristics
3. **Solution Strategy**: Design targeted fixes for the specific error type
4. **Prevention**: Ensure the fix prevents similar errors

**Common Error Patterns & Solutions:**
- "Mean of empty slice": Use fallback values when statistical calculations fail
- "All arrays must be of the same length": Ensure index alignment in operations
- "Missing values still present": Implement robust imputation with fallbacks
- Import errors: Remove any import statements (libraries are pre-imported)

{format_instructions}

Generate corrected code that specifically addresses the error while maintaining all cleaning requirements."""

        human_template = """Fix this data cleaning code that failed with an error:

**Original Code:**
```python
{original_code}
```

**Error Details:**
{error_details}

**Error Type:** {error_type}

**Dataset Context:**
{dataset_context}

**Execution Environment:**
- All standard libraries (pd, np, sklearn) are pre-imported
- DataFrame 'df' contains the original dataset
- Error occurred during execution of the above code

Analyze the error and generate corrected code that:
1. Fixes the specific error that occurred
2. Maintains all data cleaning requirements
3. Handles edge cases more robustly
4. Passes all validation checks"""

        # Create prompt template
        prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(system_template),
            HumanMessagePromptTemplate.from_template(human_template)
        ])
        
        # Create the chain
        chain = prompt | self.llm | self.code_parser
        
        logger.info("🔧 Error correction chain created")
        return chain
    
    def analyze_dataset(self, df: pd.DataFrame) -> DatasetAnalysis:
        """
        📊 Analyze dataset using LangChain structured approach
        
        Returns structured analysis instead of raw text,
        enabling better downstream processing and debugging.
        """
        
        logger.info("🔍 Starting dataset analysis with LangChain...")
        
        try:
            # Prepare comprehensive dataset information
            dataset_info = self._prepare_dataset_info(df)
            
            # Execute analysis chain with structured input
            try:
                # First attempt with structured parsing
                analysis_result = self.analysis_chain.invoke(
                    dataset_info,
                    config={"callbacks": [self.trace_handler]}
                )
                
                logger.info("✅ Dataset analysis completed successfully")
                logger.info(f"📊 Quality Score: {analysis_result.data_quality_score}/100")
                logger.info(f"🔍 Major Issues: {len(analysis_result.major_issues)}")
                
                return analysis_result
                
            except Exception as parse_error:
                logger.warning(f"⚠️ Structured analysis parsing failed: {str(parse_error)}")
                
                # Try one more time with a simpler prompt
                try:
                    logger.info("🔄 Attempting retry with simplified prompt...")
                    
                    # Create a simpler chain without complex formatting
                    simple_prompt = f"""Analyze this dataset and return valid JSON:
Dataset shape: {df.shape}
Missing values: {df.isnull().sum().sum()}
Duplicates: {df.duplicated().sum()}

Return JSON with: {{"data_quality_score": 75, "major_issues": ["example"], "recommended_actions": ["example"]}}"""
                    
                    simple_result = self.llm.invoke(simple_prompt)
                    
                    # Try to parse the simple result
                    import json
                    if hasattr(simple_result, 'content'):
                        content = simple_result.content
                    else:
                        content = str(simple_result)
                    
                    # Extract JSON from the response
                    json_start = content.find('{')
                    json_end = content.rfind('}') + 1
                    if json_start != -1 and json_end > json_start:
                        json_str = content[json_start:json_end]
                        simple_data = json.loads(json_str)
                        
                        # Create analysis from simple data
                        return DatasetAnalysis(
                            total_rows=df.shape[0],
                            total_columns=df.shape[1],
                            memory_usage_mb=df.memory_usage(deep=True).sum() / 1024 / 1024,
                            missing_values_count=df.isnull().sum().sum(),
                            duplicate_rows_count=df.duplicated().sum(),
                            numeric_columns=list(df.select_dtypes(include=[np.number]).columns),
                            categorical_columns=list(df.select_dtypes(include=['object']).columns),
                            datetime_columns=list(df.select_dtypes(include=['datetime64']).columns),
                            data_quality_score=simple_data.get("data_quality_score", 75),
                            major_issues=simple_data.get("major_issues", ["Analysis parsing failed"]),
                            recommended_actions=simple_data.get("recommended_actions", ["Use fallback cleaning"]),
                            corruption_indicators=[],
                            outlier_columns=[]
                        )
                        
                except Exception as simple_error:
                    logger.warning(f"⚠️ Simple analysis also failed: {str(simple_error)}")
                
                logger.info("🔄 Using fallback analysis...")
                # Fallback: Create basic analysis from dataset inspection
                fallback_analysis = self._create_fallback_analysis(df)
                return fallback_analysis
            
        except Exception as e:
            logger.error(f"❌ Analysis failed completely: {str(e)}")
            logger.error(f"📄 Traceback: {traceback.format_exc()}")
            raise
    
    def _create_fallback_analysis(self, df: pd.DataFrame) -> DatasetAnalysis:
        """
        🔄 Create fallback analysis when structured parsing fails
        
        This method manually analyzes the dataset and constructs a DatasetAnalysis
        object using basic pandas operations when LangChain parsing fails.
        """
        
        logger.info("🔄 Creating fallback dataset analysis...")
        
        try:
            # Basic dataset metrics
            total_rows, total_columns = df.shape
            memory_usage_mb = df.memory_usage(deep=True).sum() / 1024 / 1024
            missing_values_count = df.isnull().sum().sum()
            duplicate_rows_count = df.duplicated().sum()
            
            # Column type analysis
            numeric_columns = list(df.select_dtypes(include=[np.number]).columns)
            categorical_columns = list(df.select_dtypes(include=['object']).columns)
            datetime_columns = list(df.select_dtypes(include=['datetime64']).columns)
            
            # Quality assessment
            missing_percentage = (missing_values_count / (total_rows * total_columns)) * 100
            duplicate_percentage = (duplicate_rows_count / total_rows) * 100
            
            # Calculate basic quality score
            quality_score = 100.0
            quality_score -= min(missing_percentage * 2, 40)  # Penalize missing values
            quality_score -= min(duplicate_percentage * 1.5, 30)  # Penalize duplicates
            quality_score = max(quality_score, 0)  # Don't go below 0
            
            # Identify major issues
            major_issues = []
            if missing_values_count > 0:
                major_issues.append(f"Missing values: {missing_values_count} ({missing_percentage:.1f}%)")
            if duplicate_rows_count > 0:
                major_issues.append(f"Duplicate rows: {duplicate_rows_count} ({duplicate_percentage:.1f}%)")
            if memory_usage_mb > 100:
                major_issues.append(f"High memory usage: {memory_usage_mb:.1f} MB")
            
            # Basic recommendations
            recommended_actions = []
            if missing_values_count > 0:
                recommended_actions.append("Impute missing values using statistical methods")
            if duplicate_rows_count > 0:
                recommended_actions.append("Remove duplicate rows")
            if len(categorical_columns) > 0:
                recommended_actions.append("Optimize categorical data types")
            if memory_usage_mb > 50:
                recommended_actions.append("Optimize memory usage")
            
            # Basic corruption detection
            corruption_indicators = []
            for col in categorical_columns[:5]:  # Check first 5 categorical columns
                if df[col].astype(str).str.contains(r'\d+[a-zA-Z]+|\w+\d+', na=False).any():
                    corruption_indicators.append(f"Mixed alphanumeric patterns in {col}")
            
            # Outlier detection for numeric columns
            outlier_columns = []
            for col in numeric_columns[:5]:  # Check first 5 numeric columns
                Q1 = df[col].quantile(0.25)
                Q3 = df[col].quantile(0.75)
                IQR = Q3 - Q1
                outliers = ((df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))).sum()
                if outliers > total_rows * 0.05:  # More than 5% outliers
                    outlier_columns.append(col)
            
            # Create fallback analysis object
            fallback_analysis = DatasetAnalysis(
                total_rows=total_rows,
                total_columns=total_columns,
                memory_usage_mb=round(memory_usage_mb, 2),
                missing_values_count=missing_values_count,
                duplicate_rows_count=duplicate_rows_count,
                numeric_columns=numeric_columns,
                categorical_columns=categorical_columns,
                datetime_columns=datetime_columns,
                data_quality_score=round(quality_score, 1),
                major_issues=major_issues if major_issues else ["No major issues detected"],
                recommended_actions=recommended_actions if recommended_actions else ["Dataset appears clean"],
                corruption_indicators=corruption_indicators,
                outlier_columns=outlier_columns
            )
            
            logger.info("✅ Fallback analysis completed")
            logger.info(f"📊 Fallback Quality Score: {quality_score:.1f}/100")
            logger.info(f"🔍 Issues detected: {len(major_issues)}")
            
            return fallback_analysis
            
        except Exception as e:
            logger.error(f"❌ Even fallback analysis failed: {str(e)}")
            
            # Ultimate fallback - minimal analysis
            minimal_analysis = DatasetAnalysis(
                total_rows=len(df) if df is not None else 0,
                total_columns=len(df.columns) if df is not None else 0,
                memory_usage_mb=1.0,  # Default
                missing_values_count=0,
                duplicate_rows_count=0,
                numeric_columns=[],
                categorical_columns=[],
                datetime_columns=[],
                data_quality_score=50.0,  # Default medium score
                major_issues=["Analysis failed - using minimal assessment"],
                recommended_actions=["Basic data cleaning recommended"],
                corruption_indicators=[],
                outlier_columns=[]
            )
            
            logger.info("⚠️ Using minimal analysis due to failures")
            return minimal_analysis
    
    def generate_cleaning_code(self, df: pd.DataFrame, analysis: DatasetAnalysis) -> CleaningCode:
        """
        🤖 Generate cleaning code using LangChain structured approach
        
        Returns structured code object with metadata,
        enabling better error handling and debugging.
        """
        
        logger.info("🤖 Generating cleaning code with LangChain...")
        
        try:
            # Prepare code generation input
            generation_input = {
                "analysis_results": analysis.model_dump_json(indent=2),
                "corruption_details": ", ".join(analysis.corruption_indicators),
                "format_instructions": self.code_parser.get_format_instructions()
            }
            
            # Execute code generation chain with structured parsing
            try:
                code_result = self.code_generation_chain.invoke(
                    generation_input,
                    config={"callbacks": [self.trace_handler]}
                )
                
                # Add metadata
                code_result.model_used = config.default_model
                
                logger.info("✅ Code generation completed successfully")
                logger.info(f"📝 Generated {len(code_result.cleaning_code.split('\\n'))} lines of code")
                logger.info(f"🎯 Expected changes: {len(code_result.expected_changes)}")
                
                return code_result
                
            except Exception as parse_error:
                logger.warning(f"⚠️ Structured parsing failed: {str(parse_error)}")
                
                # Try to extract partial JSON first
                try:
                    logger.info("🔄 Attempting to extract partial JSON...")
                    partial_result = self._extract_partial_json_response(parse_error, generation_input)
                    if partial_result:
                        return partial_result
                except Exception as partial_error:
                    logger.warning(f"⚠️ Partial JSON extraction failed: {str(partial_error)}")
                
                logger.info("🔄 Using complete fallback code generation...")
                # Fallback: Use basic LLM without structured parsing
                fallback_result = self._generate_code_fallback(generation_input)
                return fallback_result
            
        except Exception as e:
            logger.error(f"❌ Code generation failed completely: {str(e)}")
            logger.error(f"📄 Traceback: {traceback.format_exc()}")
            raise
    
    def _extract_partial_json_response(self, parse_error: Exception, generation_input: Dict[str, str]) -> Optional[CleaningCode]:
        """
        🔄 Extract partial JSON response when structured parsing fails
        
        This method attempts to extract cleaning code from partial JSON responses
        that contain only some fields instead of the complete CleaningCode schema.
        """
        
        try:
            # Extract the raw response from the error message
            error_str = str(parse_error)
            
            # Look for JSON content in the error message
            if "Invalid json output:" in error_str:
                # Find the JSON part after the error description
                json_start = error_str.find('{"')
                if json_start == -1:
                    json_start = error_str.find('{')
                
                if json_start != -1:
                    # Extract potential JSON content
                    json_part = error_str[json_start:]
                    
                    # Try to find the end of JSON
                    brace_count = 0
                    json_end = 0
                    for i, char in enumerate(json_part):
                        if char == '{':
                            brace_count += 1
                        elif char == '}':
                            brace_count -= 1
                            if brace_count == 0:
                                json_end = i + 1
                                break
                    
                    if json_end > 0:
                        potential_json = json_part[:json_end]
                        
                        # Try to parse the partial JSON
                        try:
                            partial_data = json.loads(potential_json)
                            
                            # Check if we have the essential cleaning_code field
                            if "cleaning_code" in partial_data:
                                logger.info("✅ Successfully extracted cleaning code from partial JSON")
                                
                                # Construct CleaningCode with available data and defaults
                                return CleaningCode(
                                    cleaning_code=partial_data.get("cleaning_code", ""),
                                    explanation=partial_data.get("explanation", "Partially extracted code from JSON parsing failure"),
                                    expected_changes=partial_data.get("expected_changes", ["Data type optimization", "Missing value imputation", "Duplicate removal"]),
                                    estimated_processing_time=partial_data.get("estimated_processing_time", "2-5 seconds"),
                                    validation_checks=partial_data.get("validation_checks", ["Check for missing values", "Validate data types", "Confirm duplicate removal"]),
                                    potential_risks=partial_data.get("potential_risks", ["Potential data loss during type conversion"]),
                                    model_used=partial_data.get("model_used", config.default_model)
                                )
                                
                        except json.JSONDecodeError:
                            logger.warning("⚠️ Partial JSON is still invalid")
                            
            return None
            
        except Exception as e:
            logger.warning(f"⚠️ Partial JSON extraction error: {str(e)}")
            return None
    
    def _generate_code_fallback(self, generation_input: Dict[str, str]) -> CleaningCode:
        """
        🔄 Fallback code generation without structured parsing
        
        When the structured JSON output parser fails, this method generates
        code using a simpler approach and manually constructs the CleaningCode object.
        """
        
        logger.info("🔄 Using fallback code generation method...")
        
        try:
            # Create a simple prompt without JSON requirements
            fallback_prompt = f"""
You are an expert Python data scientist. Generate robust data cleaning code for this dataset.

**Dataset Analysis:**
{generation_input['analysis_results']}

**Requirements:**
- Generate ONLY executable Python code (no import statements)
- Use pre-available variables: pd, np, df
- Handle corrupted values in: {generation_input['corruption_details']}
- Ensure zero missing values in final result
- Include data validation and error checking
- AVOID chained assignment (use .loc[] or direct assignment)

**Code Structure:**
```python
# Step 1: Initialize
cleaned_df = df.copy()
print(f"Starting shape: {{cleaned_df.shape}}")

# Step 2: Your cleaning logic here
# Use .loc[] or direct assignment to avoid pandas warnings
# Example: cleaned_df.loc[:, 'column'] = cleaned_df['column'].fillna(value)

# Step 3: Final validation
assert cleaned_df.isnull().sum().sum() == 0, "Missing values still present!"
print(f"Final shape: {{cleaned_df.shape}}")
print("✅ Cleaning completed successfully!")
```

Generate the complete cleaning code:
"""

            # Use basic LLM chain without parser
            basic_chain = self.llm
            response = basic_chain.invoke(fallback_prompt)
            
            # Extract code from response
            if hasattr(response, 'content'):
                response_text = response.content
            else:
                response_text = str(response)
            
            # Extract Python code from the response
            code_lines = []
            in_code_block = False
            
            for line in response_text.split('\n'):
                if line.strip().startswith('```python'):
                    in_code_block = True
                    continue
                elif line.strip().startswith('```') and in_code_block:
                    break
                elif in_code_block:
                    code_lines.append(line)
                elif line.strip().startswith('cleaned_df') or line.strip().startswith('#') or 'pd.' in line or 'np.' in line:
                    # Also capture code that looks like Python outside code blocks
                    code_lines.append(line)
            
            # If no code blocks found, try to extract the entire response as code
            if not code_lines:
                code_lines = [line for line in response_text.split('\n') 
                             if line.strip() and not line.strip().startswith('**')]
            
            extracted_code = '\n'.join(code_lines).strip()
            
            # If still no code, provide a basic fallback
            if not extracted_code or len(extracted_code) < 50:
                logger.warning("⚠️ Could not extract meaningful code, using basic fallback")
                extracted_code = """
# Basic fallback cleaning code
cleaned_df = df.copy()
print(f"Starting shape: {cleaned_df.shape}")

# Handle missing values with proper pandas methods (avoid chained assignment)
for col in cleaned_df.columns:
    if cleaned_df[col].dtype == 'object':
        # Use mode for categorical data, fallback to 'unknown'
        mode_value = cleaned_df[col].mode()
        fill_value = mode_value.iloc[0] if len(mode_value) > 0 else 'unknown'
        # Use .loc[] to avoid chained assignment warning
        cleaned_df.loc[:, col] = cleaned_df[col].fillna(fill_value)
    else:
        # Use median for numeric data
        median_value = cleaned_df[col].median()
        # Use .loc[] to avoid chained assignment warning
        cleaned_df.loc[:, col] = cleaned_df[col].fillna(median_value)

# Remove duplicates safely
initial_rows = len(cleaned_df)
cleaned_df = cleaned_df.drop_duplicates()
final_rows = len(cleaned_df)
print(f"Removed {initial_rows - final_rows} duplicate rows")

# Final validation
assert cleaned_df.isnull().sum().sum() == 0, "Missing values still present!"
print(f"Final shape: {cleaned_df.shape}")
print("✅ Basic cleaning completed!")
"""
            
            # Manually construct CleaningCode object
            fallback_code_obj = CleaningCode(
                cleaning_code=extracted_code,
                explanation="Fallback cleaning code generated when structured parsing failed",
                expected_changes=[
                    "Remove missing values using median/mode imputation",
                    "Remove duplicate rows",
                    "Basic data type optimization"
                ],
                estimated_processing_time="< 5 seconds",
                validation_checks=[
                    "Missing values check",
                    "Duplicate removal check",
                    "Data integrity validation"
                ],
                potential_risks=[
                    "Possible data loss from aggressive cleaning",
                    "May not handle all edge cases"
                ],
                model_used=f"{config.default_model} (fallback mode)"
            )
            
            logger.info("✅ Fallback code generation completed")
            logger.info(f"📝 Generated {len(extracted_code.split('\\n'))} lines of fallback code")
            
            return fallback_code_obj
            
        except Exception as e:
            logger.error(f"❌ Even fallback code generation failed: {str(e)}")
            
            # Ultimate fallback - minimal working code
            minimal_code = """
cleaned_df = df.copy()
cleaned_df = cleaned_df.dropna()
cleaned_df = cleaned_df.drop_duplicates()
print("✅ Minimal cleaning completed!")
"""
            
            return CleaningCode(
                cleaning_code=minimal_code,
                explanation="Minimal fallback cleaning due to generation failures",
                expected_changes=["Remove missing values", "Remove duplicates"],
                estimated_processing_time="< 1 second",
                validation_checks=["Basic cleaning"],
                potential_risks=["Data loss possible"],
                model_used=f"{config.default_model} (minimal fallback)"
            )
    
    def execute_cleaning_code(self, df: pd.DataFrame, code_obj: CleaningCode) -> Tuple[bool, str, Optional[pd.DataFrame]]:
        """
        ⚡ Execute cleaning code using the existing SafeCodeExecutor
        
        Integrates LangChain-generated code with the proven execution environment.
        """
        
        logger.info("⚡ Executing cleaning code...")
        
        try:
            success, output, cleaned_df = self.code_executor.execute_with_timeout(
                code_obj.cleaning_code, 
                df
            )
            
            if success:
                logger.info("✅ Code execution successful")
                logger.info(f"📊 Result shape: {cleaned_df.shape if cleaned_df is not None else 'None'}")
            else:
                logger.warning("⚠️ Code execution failed")
                logger.warning(f"📄 Error output: {output}")
            
            return success, output, cleaned_df
            
        except Exception as e:
            error_msg = f"Execution error: {str(e)}"
            logger.error(f"❌ {error_msg}")
            return False, error_msg, None
    
    def fix_code_with_langchain(self, original_code: str, error_details: str, df: pd.DataFrame) -> CleaningCode:
        """
        🔧 Fix failed code using LangChain error correction
        
        Provides intelligent error analysis and targeted fixes
        instead of generic retry patterns.
        """
        
        logger.info("🔧 Fixing code with LangChain error correction...")
        
        try:
            # Prepare error correction input
            correction_input = {
                "original_code": original_code,
                "error_details": error_details,
                "error_type": self._classify_error(error_details),
                "dataset_context": f"Shape: {df.shape}, Columns: {list(df.columns)[:5]}...",
                "format_instructions": self.code_parser.get_format_instructions()
            }
            
            # Execute correction chain
            corrected_code = self.correction_chain.invoke(
                correction_input,
                config={"callbacks": [self.trace_handler]}
            )
            
            # Add metadata
            corrected_code.model_used = config.default_model
            
            logger.info("✅ Code correction completed")
            logger.info(f"🔧 Generated corrected version")
            
            return corrected_code
            
        except Exception as e:
            logger.error(f"❌ Code correction failed: {str(e)}")
            raise
    
    def clean_dataset(self, df: pd.DataFrame, max_attempts: int = 3) -> Dict[str, Any]:
        """
        🚀 Complete dataset cleaning pipeline using LangChain ecosystem
        
        This is the main entry point that orchestrates the entire
        cleaning process with full observability and error recovery.
        """
        
        start_time = datetime.now()
        logger.info("🚀 Starting LangChain-powered dataset cleaning pipeline...")
        
        try:
            # Step 1: Analyze dataset with structured output
            logger.info("📊 Step 1: Dataset Analysis")
            analysis = self.analyze_dataset(df)
            
            # Step 2: Generate initial cleaning code
            logger.info("🤖 Step 2: Code Generation")
            code_obj = self.generate_cleaning_code(df, analysis)
            
            # Step 3: Execute with retry logic
            logger.info("⚡ Step 3: Code Execution with Error Recovery")
            
            for attempt in range(1, max_attempts + 1):
                logger.info(f"🔄 Attempt {attempt}/{max_attempts}")
                
                success, output, cleaned_df = self.execute_cleaning_code(df, code_obj)
                
                if success and cleaned_df is not None:
                    # Success! Calculate processing time
                    processing_time = (datetime.now() - start_time).total_seconds()
                    
                    logger.info("🎉 Dataset cleaning completed successfully!")
                    logger.info(f"⏱️ Total processing time: {processing_time:.2f} seconds")
                    
                    # Return comprehensive results
                    return {
                        "success": True,
                        "cleaned_df": cleaned_df,
                        "cleaning_code": code_obj.cleaning_code,
                        "analysis": analysis.model_dump(),
                        "processing_time": processing_time,
                        "attempts_used": attempt,
                        "langchain_traces": self.trace_handler.traces,
                        "code_metadata": code_obj.model_dump()
                    }
                
                # Attempt failed - try to fix the code
                if attempt < max_attempts:
                    logger.info("🔧 Attempting to fix code with LangChain...")
                    try:
                        code_obj = self.fix_code_with_langchain(
                            code_obj.cleaning_code, 
                            output, 
                            df
                        )
                    except Exception as fix_error:
                        logger.error(f"❌ Code fixing failed: {str(fix_error)}")
                        break
            
            # All attempts failed
            processing_time = (datetime.now() - start_time).total_seconds()
            
            logger.error("❌ All cleaning attempts failed")
            
            return {
                "success": False,
                "error": f"Failed after {max_attempts} attempts. Last error: {output}",
                "analysis": analysis.dict() if 'analysis' in locals() else None,
                "processing_time": processing_time,
                "attempts_used": max_attempts,
                "langchain_traces": self.trace_handler.traces
            }
            
        except Exception as e:
            processing_time = (datetime.now() - start_time).total_seconds()
            
            logger.error(f"❌ Pipeline failed with exception: {str(e)}")
            
            return {
                "success": False,
                "error": f"Pipeline exception: {str(e)}",
                "processing_time": processing_time,
                "langchain_traces": self.trace_handler.traces,
                "exception_details": traceback.format_exc()
            }
    
    def _prepare_dataset_info(self, df: pd.DataFrame) -> Dict[str, str]:
        """Prepare comprehensive dataset information for analysis"""
        
        # Calculate memory usage
        memory_usage = df.memory_usage(deep=True).sum() / 1024 / 1024  # MB
        
        # Get column information
        column_info = {
            "numeric": list(df.select_dtypes(include=[np.number]).columns),
            "categorical": list(df.select_dtypes(include=['object']).columns),
            "datetime": list(df.select_dtypes(include=['datetime64']).columns)
        }
        
        # Sample data (first 3 rows, safe display)
        sample_data = df.head(3).to_string()
        
        # Column details with types and stats
        column_details = []
        for col in df.columns:
            details = f"{col}: {df[col].dtype}"
            if df[col].dtype in ['object']:
                unique_count = df[col].nunique()
                details += f" ({unique_count} unique values)"
            elif np.issubdtype(df[col].dtype, np.number):
                details += f" (range: {df[col].min():.2f} to {df[col].max():.2f})"
            column_details.append(details)
        
        # Missing values info
        missing_info = df.isnull().sum()
        missing_summary = [f"{col}: {count}" for col, count in missing_info.items() if count > 0]
        
        return {
            "dataset_shape": f"{df.shape[0]} rows × {df.shape[1]} columns",
            "memory_usage": f"{memory_usage:.2f}",
            "column_info": str(column_info),
            "sample_data": sample_data,
            "column_details": "\\n".join(column_details),
            "missing_values_info": "\\n".join(missing_summary) if missing_summary else "No missing values found",
            "quality_observations": f"Duplicates: {df.duplicated().sum()}, Memory efficient: {memory_usage < 100}",
            "format_instructions": self.analysis_parser.get_format_instructions()
        }
    
    def clean_dataset(self, df: pd.DataFrame, max_attempts: int = 3) -> Dict[str, Any]:
        """
        🧹 Public interface for data cleaning that matches Streamlit app expectations
        
        This implements the complete data cleaning pipeline using LangChain components.
        """
        logger.info("🧹 Starting LangChain data cleaning process...")
        start_time = time.time()
        
        try:
            # Step 1: Analyze the dataset
            logger.info("📊 Step 1: Analyzing dataset...")
            analysis = self.analyze_dataset(df)
            
            # Step 2: Generate cleaning code
            logger.info("🤖 Step 2: Generating cleaning code...")
            code_obj = self.generate_cleaning_code(df, analysis)
            
            # Step 3: Execute cleaning code with retry logic
            logger.info("⚡ Step 3: Executing cleaning code...")
            attempts_used = 0
            last_error = ""
            
            for attempt in range(max_attempts):
                attempts_used = attempt + 1
                logger.info(f"🔄 Execution attempt {attempts_used}/{max_attempts}")
                
                success, output, cleaned_df = self.execute_cleaning_code(df, code_obj)
                
                if success and cleaned_df is not None:
                    processing_time = time.time() - start_time
                    logger.info(f"✅ Data cleaning completed successfully in {processing_time:.2f}s")
                    
                    return {
                        "success": True,
                        "cleaned_df": cleaned_df,
                        "cleaning_code": code_obj.cleaning_code,
                        "analysis": analysis,
                        "processing_time": processing_time,
                        "attempts_used": attempts_used,
                        "langchain_traces": [],  # Could add LangSmith traces here
                        "metadata": {
                            "explanation": code_obj.explanation,
                            "expected_changes": code_obj.expected_changes,
                            "estimated_processing_time": code_obj.estimated_processing_time,
                            "validation_checks": code_obj.validation_checks,
                            "potential_risks": code_obj.potential_risks,
                            "model_used": code_obj.model_used
                        }
                    }
                else:
                    last_error = output
                    logger.warning(f"⚠️ Attempt {attempts_used} failed: {output}")
                    
                    # Try to fix the code for next attempt
                    if attempt < max_attempts - 1:
                        logger.info("🔧 Attempting to fix the code...")
                        try:
                            corrected_code = self.fix_code_with_langchain(
                                code_obj.cleaning_code, 
                                output, 
                                df
                            )
                            code_obj = corrected_code
                        except Exception as fix_error:
                            logger.warning(f"⚠️ Code fixing failed: {str(fix_error)}")
            
            # All attempts failed
            processing_time = time.time() - start_time
            logger.error(f"❌ All {max_attempts} attempts failed")
            
            return {
                "success": False,
                "error": f"All {max_attempts} cleaning attempts failed. Last error: {last_error}",
                "attempts_used": attempts_used,
                "processing_time": processing_time,
                "analysis": analysis,
                "last_error": last_error
            }
                    
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"❌ Clean dataset failed: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "attempts_used": 1,
                "processing_time": processing_time
            }
    
    def _classify_error(self, error_message: str) -> str:
        """Classify error type for targeted fixing"""
        error_msg_lower = error_message.lower()
        
        if "mean of empty slice" in error_msg_lower:
            return "STATISTICAL_CALCULATION_ERROR"
        elif "missing values still present" in error_msg_lower:
            return "MISSING_VALUES_ERROR"
        elif "all arrays must be of the same length" in error_msg_lower:
            return "LENGTH_MISMATCH_ERROR"
        elif "import" in error_msg_lower:
            return "FORBIDDEN_IMPORT_ERROR"
        else:
            return "UNKNOWN_ERROR"

# Example usage and testing
def main():
    """
    🧪 Test the LangChain agent with sample data
    """
    
    print("🧪 Testing LangChain Data Cleaning Agent")
    print("="*50)
    
    # Check configuration
    validation = config.validate_api_keys()
    if not validation["google_gemini"]:
        print("❌ Google Gemini API key required")
        print("💡 Please set GOOGLE_API_KEY in your .env file")
        return
    
    # Create sample data with issues
    sample_data = {
        'numeric_col': [1.5, 2.3, None, 4.1, '5.6corrupted'],
        'category': ['A', 'B', None, 'C', 'A'],
        'messy_numbers': ['1.1abc', '2.2', 'corrupted', '4.4', '5.5xyz']
    }
    df = pd.DataFrame(sample_data)
    
    print(f"📊 Sample dataset created: {df.shape}")
    print(f"🔍 Missing values: {df.isnull().sum().sum()}")
    
    # Initialize and test agent
    try:
        agent = LangChainDataCleaningAgent()
        
        # Run cleaning pipeline
        result = agent.clean_dataset(df)
        
        if result["success"]:
            print("✅ Cleaning successful!")
            print(f"⏱️ Processing time: {result['processing_time']:.2f} seconds")
            print(f"🔄 Attempts used: {result['attempts_used']}")
            print(f"📊 Final shape: {result['cleaned_df'].shape}")
            print(f"📈 LangChain traces: {len(result['langchain_traces'])}")
        else:
            print("❌ Cleaning failed")
            print(f"❗ Error: {result['error']}")
            
    except Exception as e:
        print(f"❌ Agent initialization failed: {str(e)}")
        print("💡 Check your API keys and configuration")

if __name__ == "__main__":
    main()